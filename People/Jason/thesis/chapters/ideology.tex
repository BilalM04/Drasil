The focus on this work is based on the ``simple'' idea that if you understand
how you can do something, then you should be able to do something (\(p \implies
p\)).

\section{Knowledge Capture \& Encoding}

As a software developer working to build a new piece of software, one might find
that they are writing ``a lot of the same code'' as their or other pre-existing
software projects. One might consider building a library, shared between all
projects for some common functionality/tooling, this is a large improvement for
their program --- being able to reuse their code is great for debugging and
removing the possibility of bugs when stable and tested code is used.

\intodo{It is also great for time spent, stability, less errors, saving time in
    the future, creating more possibilities in locating areas where we can
    abstract, and capturing tacit knowledge.}

Commonly, one looks to use mature libraries and frameworks to underpin their
projects, occasionally without guarantee that connecting these libraries is
safe. As general purpose programming languages are often also used,
misunderstandings of tacit project knowledge may also cause errors.
Unfortunately, this programming methodology takes significant time until a
working product is formed with minimal bugs.

\intodo{Above paragraph is awkward.}

If one originally sets out to build a program that does something they
understand very well and each component of every step of the grand scheme of the
program was understood, the development of their related software should be a
clear matter of principled engineering. However, with this existing programming
methodology, it is not yet simple enough yet to get reliable programs.

Optimally, they would use their natural language to perfectly describe their
problem to their computer and have it magically give them a program that does
exactly what they wanted. Unfortunately, it is difficult to have computers
systematically understand and act on natural language as well as us humans can.
However, we can mimic a computer ``understanding'' an equivalent speech through
having the human write the same knowledge using a domain-specific language.
Additionally, through sequencing and connecting domain-specific languages, we
can effectively model what they are trying to build, allowing the computer to be
able to better understand what they are trying to build. With enough effort, the
computer should be able to generate some artifact that ultimately represents
what they were trying to build. Note, however, that this idea likely only
thrives in domains of knowledge that is ``well-understood''
\cite{well-understood}.

\intodo{Discuss the roles of the domain expert, the end-user (a modeller), and the final end-user (the softifact user)}
% The domain-expert's job is to create the domain-specific languages and tools.
% target: Importance of the domain-expert for the end-user, and results

As a domain expert transcribing knowledge encodings of some well-understood
domain, one will largely be discussing the ways in which pieces of knowledge are
\textit{constructed} and \textit{relate to each other}. In order for this
abstract knowledge encodings to be \textit{usable} in some way, it is vital to
have ``names'' (\textit{types}) for the knowledge encodings. In working to
capture the working knowledge of a domain, it's of utmost importance to ensure
that all ``instances'' of your ``names'' (types) are \textit{always} usable in
some meaningful way. In other words, all knowledge encodings should create a
stringent, explicit set of rules for which all ``instances'' should conform to,
and, arguably, also creates a justification for the need to create that
particular knowledge/data type. As such, optimally, a domain expert would write
their knowledge encodings and renderers in a general purpose programming
language with a sound type system (e.g., Haskell, Agda, Java, etc.) --
preferring ones with a type system based on formal type theories for their
feature richness.
