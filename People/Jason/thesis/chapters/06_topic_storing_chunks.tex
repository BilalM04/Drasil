\chapter{``Store All The Things''}
\label{chap:storingChunks}

\begin{writingdirectives}

      \item \textit{Problem}: Drasil can have any number of \textit{types} of
            chunks involved in any particular generation operation. While the
            types are useful in many regards, the types encumber us when we try
            to reference a specific chunk (by its \UID{}) without surrounding
            type information, which may not be important.

      \item Drasils \ChunkDB{} (\refOriginalChunkDBHaskell) collects chunks
            using a series of maps, one for each chunk type.

      \item \textit{Practical Problems}:
            \begin{itemize}

                  \item Does not allow us to ignore type information when its
                        not really needed. i.e., in areas where we use bounded
                        polymorphism.
                  
                        \intodo{Explain when it's not really needed (i.e.,
                        functions that just take any chunk that satisfy a
                        constraint and use them in some area, or just grabbing
                        the UID or the references of the chunk.)}

                  \item Scaling against new types of chunks.
                  
                  \item Scaling against type parameters.
                  
                  \item Data consistency.
                  
                  \item Can't properly answer ``what chunk does X UID refer
                        to?'' No definitive answer to examining a specific chunk
                        by its \UID{}.

            \end{itemize}

      \item \textit{Solution}: Without discard, mask the type information,
            ignoring differences in the chunks other than that which is
            minimally required of them, and unmask it as needed.

      \item \textit{Practical Solution}: We can use \ExistentialQuantification{}
            with new data type that can carry anything that provides a minimum
            needed functionality (i.e., providing \UID{}s for their own data,
            and for references). In doing this, we effectively ``drop the type
            information'' when it's placed into the chunk database. However, we
            allow for that chunk to be unpacked (with type information retained)
            later through using Haskell's \inlineHs{Data.Typeable} (part of
            \inlineHs{base} package). As such, we can merge the series of maps
            into a single map that collects all chunks.

\end{writingdirectives}

In Drasil vernacular, as discussed in \Cref{chap:drasil}, we call encoded
fragments of knowledge, ``chunks.'' In practice, users encode chunks using
Haskells basic \inlineHs{data} types (example later), tagging it with a
\ACF{uid}, typically contained within the record. \acsp{uid} are represented by
the \UID{} data type\todo{ref Original UID Haskell}. For example, \todo{ref
example chunk definition below} the below example chunk definition represents a
commonly used packet of data associated with names.

\intodo{Example of an uncomplicated chunks definition.}

\intodo{Discuss what parts are necessary for a chunk to be considered ``valid.''
      i.e., a UID, a list of references to referred chunks, and a type.}

In the above example, the chunk belongs to a specific \textit{type}
classification\todo{ref its type definition, from the appendix}. Drasil
leverages Haskells type system to create a system of reasoning about chunks. As
such, when we create instances of chunks, they are ``typed'' with a single fully
monomorphic type signature. Commonly, we create chunks to discuss relations
between other chunks. As such, chunks commonly also refer to other instances of
chunks, but, instead of storing whole constituent chunks within them, we store
\UID{} references to those constituent chunks. In doing this, we ensure that all
references to that chunk refer to the same piece of immutable data\todo{Is
memory usage a real issue with this? I also imagine this allows post-facto chunk
creation too.}.

\intodo{Discuss classy lenses built.}

Searching for chunks by their \UID{}s requires us to have somewhere to search
from. Drasil requires developers to collect all of their relevant chunks inside
of an encompassing ``chunk database.'' The ``chunk database'' (\ChunkDB{}) is
built (as seen in \refOriginalChunkDBHaskell{}) using a series of maps
(\refOriginalChunkDBTypeMapsHaskell) that map \UID{} keys to chunk data. Each
map is a map from a \UID{} to a specific data monomorphic data type. As such, in
order to access a chunk by its \UID{}, the associated type of the chunk must be
known, even if operations we intended to use on the grabbed chunk are generic,
applicable to any similar category of chunks (such as those satisfying a
particular typeclass constraint set), or all ``chunks''. Additionally, since
there is one map per monomorphic type, it means that all chunk types must be
known and coded in the \ChunkDB{} beforehand. Of course, this means that set of
types that Drasil can work with is fixed, and, that if we have \(N\) types (with
no type parameters), then there must be \(N\) maps in the \ChunkDB{} data type.
However, for each chunk type with type parameters, each argument combination
would need to also be registered. Together, this leads to an ever-growing series
of maps, and scales poorly against new knowledge being ``taught'' to Drasil.
Additionally, since we have a collection of maps, ensuring \UID{} collisions
never occur becomes tedious.

\section{Scaling Against New Types}

Fundamentally, the issue with the \ChunkDB{} is that it caters to each
individual type by creating a map for each type, leading to tedious busy work to
make up for inflexibility.

In order to scale against new types, we need to make the database maps
type-agnostic, merging them all together. It should contain no hard-coded
references to any specific type, but describe what kinds of types are admissible
(which should be any valid chunk). However, this isn't to say that we should
erase all types. Rather, we should mask the type information for the purpose of
storage and minimum viable usage, but ensure that the type information can be
unmasked for retrieval and normal usage.

The question: how can we achieve this?

To collapse the series of maps into a single one, we need to have a common data
type for the maps ``value'' type. 

\intodo{Attempt to create a ``Chunk t'' type, but then note that a type needs to
      have a type parameters, but that we can ignore them through
      ExistentialQuantification.}

So, we create one:

\begin{pseudohaskell}{Basic Chunk Box}{basicChunkBox}
{-# LANGUAGE ExistentialQuantification #-}
...
data Chunk = forall a. Chunk a
\end{pseudohaskell}

Great! Now we can create a single map for our chunk collection.

\begin{pseudohaskell}{New Chunk Database Map}{newChunkDatabaseMap}
type ChunkDB = Map UID Chunk
\end{pseudohaskell}

Ok, now we've created a mechanism to collapse all of our chunk maps into one,
but, we've encountered an issue: we've neglected retrieval functionality. Let's
see:

\begin{pseudohaskell}{Broken QuantityDict Chunk Retriever}{brokenChunkRetriever}
retrieveQD :: UID -> ChunkDB -> Maybe QuantityDict
retrieveQD u cdb = do
    (Chunk expectedQd) <- lookup u cdb
    pure expectedQd
\end{pseudohaskell}

\Chunk{}s are currently an informational void. So, this results in a type
error\todo{Show the type error here.}. Haskell is unable to create the infinite
type coercion from \inlineHs{expectedQd}'s unknown type to a \QuantityDict{}.

So, how can we try to fix this? \inlineHs{Data.Typeable} to the rescue!
\inlineHs{Data.Typeable} allows us to create constrained types with extra
functionality for casting (amongst other common reflection operations). First,
we need to alter our \Chunk{} data type to make the contained data satisfy the
\Typeable{} constraint that the \Typeable{} module needs for most of its
functionality. As of \acs{ghc} 7.10 (for which our targeted version of 8+ is
newer than), \acs{ghc} automatically instantiates the \Typeable{} typeclass for
all types.

\begin{pseudohaskell}{Examinable Chunk Box}{examinableChunkBox}
{-# LANGUAGE ExistentialQuantification #-}
...
data Chunk = forall a. Typeable a => Chunk a
\end{pseudohaskell}

Ok, now we should be able to retrieve chunks, and cast the chunk value types as
needed.

\begin{pseudohaskell}{Working QuantityDict Chunk Retriever}{workingChunkRetriever}
retrieveQD :: UID -> ChunkDB -> Maybe QuantityDict
retrieveQD u cdb = do
    (Chunk expectedQd) <- lookup u cdb
    cast expectedQd
\end{pseudohaskell}

To sum up, at this point:

\begin{itemize}

      \item We were able to mask individual chunk types by hiding them in
            \Chunk{} boxes, allowing us to avoid discussing specific chunk types
            when forming our \ChunkDB{}.

      \item \ChunkDB{} is now merely a single map that allows us to easily
            ensure that there are no \UID{} collisions.

      \item \ChunkDB{} scales against new chunk type creation because it
            discusses no specific types as it only discusses types through
            constraints. Through this, it scales against the creation of type
            parameters for Haskell-level types.

\end{itemize}

\intodo{Discuss adding a few more constraints to the Chunk-allowable types. They
      should satisfy HasUID, HasReferences, and Dumpable.}

One notable and commonly used feature of the previous generation of the
\ChunkDB{} was that it allowed the user to grab \textit{all} chunks of a
particular type. We can re-create this for this new \ChunkDB{} as well by using
\inlineHs{Data.Typeable}s \TypeRep{} signature representation of Haskell types:

\begin{pseudohaskell}{Grabbing All Chunks from the New ChunkDB}{grabAllChunksFromNewChunkDB}
todo :: _
\end{pseudohaskell}

\intodo{I just need an example above, its kind of boring to write though. It
      would need to show a function that grabs chunks by a specific TypeRep and
      an example of how to use it.}

However, this is something of an expensive and commonly performed task, so it's
inefficient. So, in order to make the \ChunkDB{} more ``industrial-strength,''
we can add an extra mechanism for caching in various ways to trade a bit of
memory for a frequent and expensive search operation.

\intodo{Continue here!}

\intodo{How can we mask the types and unmask them later?}

\intodo{What is common to all chunks? What do they all need to satisfy?}

\intodo{Discuss current setup of chunks being built as nesting dolls.}

\intodo{Rewrite the point form notes in Storing Chunks chapter.}

\begin{itemize}

      \item Problems occur:
            \begin{itemize}

                  \item \UID{} collisions

                  \item Difficult to ascertain what a specific chunk type is
                        from a \UID{}

                  \item ``ChunkDB'' is not a stable core across Drasil-like
                        projects (ones that thrive on the same ``knowledge-based
                        programming'' ideology). \ChunkDB{}s are essentially the
                        ``scope'' of a system.

            \end{itemize}

      \item Solution:
            \begin{itemize}

                  \item Merge the maps!

                  \item The key would be the same; a \UID{}.

                  \item The value type?

                  \item An existentially quantified \inlineHs{Data.Typeable.Typeable}!

                  \item e.g., \inlineHs{data Chunk = forall a. Typeable => Chunk a}.

            \end{itemize}

      \item But wait! We're missing a few things from chunks:
            \begin{itemize}

                  \item What knowledge does the chunk rely on already having
                        been ``registered'' in the database and ready?

                  \item They should have \UID{}s; where's our guarantee?

                  \item Debugging will be difficult; need an interface to dump
                        all information of a chunk quickly.

            \end{itemize}

      \item Ok, revise: \inlineHs{data Chunk = forall a. (Typeable a, HasUID a, HasChunkRefs a, Dumpable a) => Chunk a}

      \item Ok, much better now.

      \item Or is it? Still many problems!
            \begin{itemize}

                  \item How do we explain ``Data.Typeable''?

                  \item And ``HasUID''?

                  \item And ``HasChunkRefs''?

                  \item And ``Dumpable''?

            \end{itemize}

      \item Well, at the very least, now we're able to merge the ``chunk'' maps
            and fix many of the pre-existing problems (we're almost there!).
            However, now we're relying too much on Haskell. How do we explain
            those parts?

      \item Also, what are \UID{}s really? Do their information carry any real
            information? \textit{Rigid designators}.

\end{itemize}

\intodo{Move nearly everything below to the Future Work chapter.}

\section{Future Work}

\subsection{Encodings}

\begin{itemize}

      \item With the above new definition of ``chunks'', they still remain a
            very vague idea, and still \textit{deeply embedded} (a place to
            recognize an encoding might be appropriate!) in Haskell.

      \item What are the kinds of chunks that can exist? What can be in a chunk,
            and what are we missing from the existing list of chunks?

      \item The problem with that is that we lose a lot of information by
            writing Haskell, and leaving the knowledge in the form of Haskell.

      \item We need to de-embed all chunks so that we can obtain a tangible
            understanding of them.

      \item Through de-embedding the chunks, we will also be forced to de-embed
            everything with it. This is including the ways in which we transform
            and generate ``new''-ish knowledge (not necessarily new types/kinds
            of knowledge, but new instances of types).

\end{itemize}


\begin{enumerate}

      \item What is a ``chunk''?
            \begin{itemize}
                  \item A ``chunk instance'' is a single \textit{term} of a
                        language.
                  \item A ``chunk type'' is a language itself.
            \end{itemize}

      \item What is a ``transformer''?
            \begin{itemize}
                  \item A ``transformer'' is a conversion of a term written in a
                        language into another term, potentially in another language.
                  \item Transformers rely on a well-understood dissection of
                        knowledge (contained in a chunk type/language) in order
                        transform it (potentially with other terms/information
                        as well) into another term.
            \end{itemize}

\end{enumerate}
